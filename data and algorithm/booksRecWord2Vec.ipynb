{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import downloader\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial import distance\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "glove_vectors = gensim.downloader.load('word2vec-google-news-300')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v2/rwg0t7796jsbrq_0j88y5mk40000gn/T/ipykernel_25695/1247681004.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_books = pd.read_csv(\"Books.csv\")\n"
     ]
    }
   ],
   "source": [
    "def Compute_ISBN_to_Title(df_merged):\n",
    "    ISBN_to_Title = {}\n",
    "    for row in df_merged.index:\n",
    "        title = df_merged[\"Book-Title\"][row]\n",
    "        isbn = df_merged[\"ISBN\"][row]\n",
    "        ISBN_to_Title[isbn] = title\n",
    "    return ISBN_to_Title\n",
    "\n",
    "def merge_book_and_summary(df_summary, df_books):\n",
    "    df_merged = pd.merge(df_summary, df_books, how='inner', on =['Book-Title'])\n",
    "    df_merged = df_merged.drop(['Code1','Code2','Code3','Publisher', 'Year-Of-Publication_x', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'Book-Author_y', 'Year-Of-Publication_y'], axis=1)\n",
    "    df_merged = df_merged[df_merged['Book-Title'] != 'Deathstalker Rebellion']\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "df_books = pd.read_csv(\"Books.csv\")\n",
    "df_summary = pd.read_csv('booksummaries/booksummaries.txt', sep = '\\t')\n",
    "df_summary.columns = ['Code1', 'Code2', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Code3', 'Book-Summary']\n",
    "ISBN_to_Title = Compute_ISBN_to_Title(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Book2Vec(df_merged):\n",
    "    title_dict = {}\n",
    "    summary_dict = {}\n",
    "\n",
    "    for row in df_merged.index:\n",
    "        title = df_merged['Book-Title'][row]\n",
    "        summary = df_merged['Book-Summary'][row]\n",
    "        summary_nonum = re.sub(r'\\d+', '', summary) #remove number\n",
    "        tokenizer = RegexpTokenizer(r'\\w+') #remove punctuation\n",
    "        summary_tokens = tokenizer.tokenize(summary_nonum) \n",
    "        filtered_summary_tokens = [w for w in summary_tokens if not w.lower() in stop_words] #remove stop words\n",
    "\n",
    "        summary_vectors = np.zeros(300)\n",
    "    \n",
    "        n = 0\n",
    "        for summary_token in filtered_summary_tokens:\n",
    "            try:\n",
    "                summary_token_vec = glove_vectors[summary_token]\n",
    "            except:\n",
    "                summary_token_vec = np.zeros(300)\n",
    "            summary_vectors += summary_token_vec\n",
    "            n += 1\n",
    "        summary_dict[title] = summary_vectors / n\n",
    "    \n",
    "    return summary_dict\n",
    "\n",
    "df_merged = merge_book_and_summary(df_summary, df_books)\n",
    "summary_dict = compute_Book2Vec(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "def compute_books_distance(summary_dict):\n",
    "    books_count = len(summary_dict)\n",
    "    books_distance = np.zeros(shape=(books_count, books_count))\n",
    "    #print(books_count)\n",
    "    summary_list = list(summary_dict)\n",
    "\n",
    "    i = 0\n",
    "    for key1 in summary_dict:\n",
    "        j = 0\n",
    "        summary_vec1 = summary_dict[key1]\n",
    "        for key2 in summary_dict:\n",
    "            summary_vec2 = summary_dict[key2]\n",
    "            dst = distance.euclidean(summary_vec1, summary_vec2)\n",
    "            if dst == 0: #same book:\n",
    "                dst = 100000\n",
    "            books_distance[i][j] = dst\n",
    "            j+=1\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "    \n",
    "        i+=1\n",
    "    \n",
    "    return books_distance\n",
    "\n",
    "books_distance = compute_books_distance(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Little Boy Blue'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mostSimilar_title(title, summary_dict, books_distance):\n",
    "    summary_list = list(summary_dict)\n",
    "    input_distance = books_distance[summary_list.index(title)]\n",
    "    closest_book_idx = np.argmin(input_distance)\n",
    "    return summary_list[closest_book_idx]\n",
    "\n",
    "def get_mostSimilar_isbn(isbn, summary_dict, books_distance, ISBN_to_Title):\n",
    "    title = ISBN_to_Title[isbn]\n",
    "    return get_mostSimilar_title(title, summary_dict, books_distance)\n",
    "\n",
    "get_mostSimilar_isbn(\"345316413X\", summary_dict, books_distance, ISBN_to_Title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbb39bc871e7848362a0c6dcbdac16925c4e41c1ea31b4ffde16ac0c0ba5ae0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
